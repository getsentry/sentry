# Generated by Django 5.2.1
import logging

from django.conf import settings
from django.db import migrations
from django.db.backends.base.schema import BaseDatabaseSchemaEditor
from django.db.migrations.state import StateApps

from sentry.new_migrations.migrations import CheckedMigration
from sentry.utils import redis
from sentry.utils.query import RangeQuerySetWrapper

logger = logging.getLogger(__name__)

ISSUE_STREAM_DETECTOR_NAME = "Issue Stream"


def backfill_issue_stream_detector_workflows(
    apps: StateApps, schema_editor: BaseDatabaseSchemaEditor
) -> None:
    """
    Backfill issue stream detectors and connecting them to the error detector's workflows.
    """
    Detector = apps.get_model("workflow_engine", "Detector")
    DetectorWorkflow = apps.get_model("workflow_engine", "DetectorWorkflow")

    backfill_key = "backfill_issue_stream_detector_workflows"
    redis_client = redis.redis_clusters.get(settings.SENTRY_MONITORS_REDIS_CLUSTER)

    progress_id = int(redis_client.get(backfill_key) or 0)

    error_detectors = Detector.objects.filter(type="error", id__gt=progress_id).prefetch_related(
        "detectorworkflow_set"
    )

    count = 0
    for error_detector in RangeQuerySetWrapper(error_detectors):
        issue_stream_detector, _ = Detector.objects.get_or_create(
            type="issue_stream",
            project_id=error_detector.project_id,
            defaults={"config": {}, "name": ISSUE_STREAM_DETECTOR_NAME},
        )
        detector_workflows = error_detector.detectorworkflow_set.all()
        DetectorWorkflow.objects.bulk_create(
            [
                DetectorWorkflow(
                    detector_id=issue_stream_detector.id, workflow_id=detector_workflow.workflow_id
                )
                for detector_workflow in detector_workflows
            ],
            ignore_conflicts=True,
        )
        redis_client.set(backfill_key, error_detector.id, ex=60 * 60 * 24 * 7)

        count += 1

        if count % 1000 == 0:
            logger.info(
                "Progress update",
                extra={
                    "count": count,
                    "current_detector_id": error_detector.id,
                },
            )
            redis_client.set(backfill_key, error_detector.id, ex=60 * 60 * 24 * 7)


class Migration(CheckedMigration):
    # This flag is used to mark that a migration shouldn't be automatically run in production.
    # This should only be used for operations where it's safe to run the migration after your
    # code has deployed. So this should not be used for most operations that alter the schema
    # of a table.
    # Here are some things that make sense to mark as post deployment:
    # - Large data migrations. Typically we want these to be run manually so that they can be
    #   monitored and not block the deploy for a long period of time while they run.
    # - Adding indexes to large tables. Since this can take a long time, we'd generally prefer to
    #   run this outside deployments so that we don't block them. Note that while adding an index
    #   is a schema change, it's completely safe to run the operation after the code has deployed.
    # Once deployed, run these manually via: https://develop.sentry.dev/database-migrations/#migration-deployment

    is_post_deployment = True

    dependencies = [
        ("workflow_engine", "0093_add_action_config_index"),
    ]

    operations = [
        migrations.RunPython(
            backfill_issue_stream_detector_workflows,
            migrations.RunPython.noop,
            hints={
                "tables": [
                    "workflow_engine_detector",
                    "workflow_engine_detectorworkflow",
                ]
            },
        ),
    ]
