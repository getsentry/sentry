# Generated by Django 5.2.1
import logging
from collections.abc import Sequence
from datetime import datetime
from enum import Enum
from typing import Any

from django.db import migrations
from django.db.backends.base.schema import BaseDatabaseSchemaEditor
from django.db.migrations.state import StateApps
from snuba_sdk import Column, Condition, Op

from sentry import eventstore
from sentry.new_migrations.migrations import CheckedMigration
from sentry.snuba.dataset import Dataset

logger = logging.getLogger(__name__)


class EventOrdering(Enum):
    LATEST = ["project_id", "-timestamp", "-event_id"]
    OLDEST = ["project_id", "timestamp", "event_id"]
    RECOMMENDED = [
        "-replay.id",
        "-trace.sampled",
        "num_processing_errors",
        "-profile.id",
        "-timestamp",
        "-event_id",
    ]


def get_oldest_or_latest_event(
    group: Any,
    ordering: EventOrdering,
    conditions: Sequence[Condition] | None = None,
    start: datetime | None = None,
    end: datetime | None = None,
) -> Any:
    dataset = Dataset.IssuePlatform

    all_conditions = [
        Condition(Column("project_id"), Op.IN, [group.project.id]),
        Condition(Column("group_id"), Op.IN, [group.id]),
    ]

    if conditions:
        all_conditions.extend(conditions)

    events = eventstore.backend.get_events_snql(
        organization_id=group.project.organization_id,
        group_id=group.id,
        start=start,
        end=end,
        conditions=all_conditions,
        limit=1,
        orderby=ordering.value,
        referrer="Group.get_latest",
        dataset=dataset,
        tenant_ids={"organization_id": group.project.organization_id},
    )

    if events:
        return events[0].for_group(group)

    return None


def backfill_metric_issue_detectorgroup(
    apps: StateApps, schema_editor: BaseDatabaseSchemaEditor
) -> None:
    """
    Backfill the DetectorGroup table for metric issues.
    """
    Group = apps.get_model("sentry", "Group")
    DetectorGroup = apps.get_model("workflow_engine", "DetectorGroup")
    Detector = apps.get_model("workflow_engine", "Detector")

    for group in Group.objects.filter(type=8001, detectorgroup__isnull=True).select_related(
        "project"
    ):  # metric issues
        # figure out the detector
        latest_event = get_oldest_or_latest_event(group, EventOrdering.LATEST)
        if not latest_event:
            DetectorGroup.objects.create(
                group_id=group.id,
                detector_id=None,
            )
            logger.info(
                "No latest event found for group, creating DetectorGroup with null detector",
                extra={"group_id": group.id},
            )
            continue

        occurrence = latest_event.occurrence
        if not occurrence:
            logger.info(
                "No occurrence found for latest event", extra={"event_id": latest_event.event_id}
            )
            continue

        detector_id = occurrence.evidence_data.get("detector_id")
        if detector_id is None:
            logger.info(
                "No detector id found for occurrence", extra={"occurrence_id": occurrence.id}
            )
            continue

        # try to fetch detector
        detector = Detector.objects.filter(id=detector_id).first()
        if detector is None:
            DetectorGroup.objects.create(
                group_id=group.id,
                detector_id=None,
            )
            logger.info(
                "Creating DetectorGroup with null detector",
                extra={"group_id": group.id, "detector_id": detector_id},
            )
            continue

        DetectorGroup.objects.create(
            group_id=group.id,
            detector_id=detector.id,
        )
        logger.info(
            "Creating DetectorGroup",
            extra={"group_id": group.id, "detector_id": detector_id},
        )


class Migration(CheckedMigration):
    # This flag is used to mark that a migration shouldn't be automatically run in production.
    # This should only be used for operations where it's safe to run the migration after your
    # code has deployed. So this should not be used for most operations that alter the schema
    # of a table.
    # Here are some things that make sense to mark as post deployment:
    # - Large data migrations. Typically we want these to be run manually so that they can be
    #   monitored and not block the deploy for a long period of time while they run.
    # - Adding indexes to large tables. Since this can take a long time, we'd generally prefer to
    #   run this outside deployments so that we don't block them. Note that while adding an index
    #   is a schema change, it's completely safe to run the operation after the code has deployed.
    # Once deployed, run these manually via: https://develop.sentry.dev/database-migrations/#migration-deployment

    is_post_deployment = True

    dependencies = [
        ("sentry", "1003_group_history_prev_history_safe_removal"),
        ("workflow_engine", "0098_detectorgroup_detector_set_null"),
    ]

    operations = [
        migrations.RunPython(
            backfill_metric_issue_detectorgroup,
            migrations.RunPython.noop,
            hints={
                "tables": [
                    "workflow_engine_detectorgroup",
                    "sentry_groupedmessage",
                ]
            },
        ),
    ]
