# Generated by Django 5.1.7 on 2025-04-09 23:57

import logging
from collections import defaultdict
from datetime import datetime
from enum import Enum
from typing import TYPE_CHECKING, Any

from django.conf import settings
from django.db import migrations, router, transaction
from django.db.backends.base.schema import BaseDatabaseSchemaEditor
from django.db.migrations.state import StateApps

from sentry.new_migrations.migrations import CheckedMigration
from sentry.utils import redis
from sentry.utils.iterators import chunked
from sentry.utils.query import RangeQuerySetWrapperWithProgressBarApprox

if TYPE_CHECKING:
    from sentry.models.activity import Activity as ActivityModelType


logger = logging.getLogger(__name__)

CHUNK_SIZE = 100


# copied constants and enums
class ActivityType(Enum):
    SET_UNRESOLVED = 2
    SET_REGRESSION = 6
    SET_RESOLVED = 1
    SET_RESOLVED_IN_RELEASE = 13
    SET_RESOLVED_BY_AGE = 15
    SET_RESOLVED_IN_COMMIT = 16
    SET_RESOLVED_IN_PULL_REQUEST = 21


RESOLVED_ACTIVITY_TYPES = [
    ActivityType.SET_RESOLVED.value,
    ActivityType.SET_RESOLVED_IN_RELEASE.value,
    ActivityType.SET_RESOLVED_BY_AGE.value,
    ActivityType.SET_RESOLVED_IN_COMMIT.value,
    ActivityType.SET_RESOLVED_IN_PULL_REQUEST.value,
]


class GroupStatus:
    UNRESOLVED = 0
    RESOLVED = 1


# end copy


def get_open_periods_for_group(
    apps: StateApps,
    group_id: int,
    status: int,
    project_id: int,
    first_seen: datetime,
    activities: list[Any],
    GroupOpenPeriod: Any,
) -> list[Any]:
    # Filter to REGRESSION and SET_RESOLVED_XX activties to find the bounds of each open period.
    # The only UNRESOLVED activity we would care about is the first UNRESOLVED activity for the group creation,
    # but we don't create an entry for that.
    open_periods = []
    start: datetime | None = None
    end: datetime | None = None
    end_activity: ActivityModelType | None = None

    # Handle currently open period
    if status == GroupStatus.UNRESOLVED and len(activities) > 0:
        open_periods.append(
            GroupOpenPeriod(
                group_id=group_id,
                project_id=project_id,
                date_started=activities[0].datetime,
                date_ended=None,
                resolution_activity=None,
                user_id=None,
            )
        )
        activities = activities[1:]

    for activity in activities:
        if activity.type in RESOLVED_ACTIVITY_TYPES:
            end = activity.datetime
            end_activity = activity
        elif activity.type == ActivityType.SET_REGRESSION.value:
            start = activity.datetime
            if end is None:
                logger.error(
                    "No end activity found for group open period backfill",
                    extra={"group_id": group_id, "starting_activity": activity.id},
                )
            if start is not None and end is not None:
                if start > end:
                    logger.error(
                        "Open period has invalid start and end dates",
                        extra={"group_id": group_id},
                    )
                    return []

                open_periods.append(
                    GroupOpenPeriod(
                        group_id=group_id,
                        project_id=project_id,
                        date_started=start,
                        date_ended=end,
                        resolution_activity=end_activity,
                        user_id=end_activity.user_id if end_activity else None,
                    )
                )
                end = None
                end_activity = None
    # Add the very first open period, which has no UNRESOLVED activity for the group creation
    open_periods.append(
        GroupOpenPeriod(
            group_id=group_id,
            project_id=project_id,
            date_started=first_seen,
            date_ended=end if end else None,
            resolution_activity=end_activity,
            user_id=end_activity.user_id if end_activity else None,
        )
    )
    return open_periods


def _backfill_group_open_periods(
    apps: StateApps, group_data: list[tuple[int, datetime, int, int]]
) -> None:
    GroupOpenPeriod = apps.get_model("sentry", "GroupOpenPeriod")
    Activity = apps.get_model("sentry", "Activity")

    group_ids = [group_id for group_id, _, _, _ in group_data]
    groups_with_open_periods = set(
        GroupOpenPeriod.objects.filter(group_id__in=group_ids)
        .values_list("group_id", flat=True)
        .distinct()
    )

    group_ids = [group_id for group_id in group_ids if group_id not in groups_with_open_periods]
    # Filter the relevant activities for groups that need to be backfilled.
    activities = defaultdict(list)
    for activity in Activity.objects.filter(
        group_id__in=group_ids,
        type__in=[ActivityType.SET_REGRESSION.value, *RESOLVED_ACTIVITY_TYPES],
    ).order_by("-datetime"):
        activities[activity.group_id].append(activity)

    open_periods = []
    for group_id, first_seen, status, project_id in group_data:
        # Skip groups that already have open periods
        if group_id in groups_with_open_periods:
            continue

        open_periods.extend(
            get_open_periods_for_group(
                apps,
                group_id,
                status,
                project_id,
                first_seen,
                activities[group_id],
                GroupOpenPeriod,
            )
        )

    with transaction.atomic(router.db_for_write(GroupOpenPeriod)):
        GroupOpenPeriod.objects.bulk_create(open_periods)


def backfill_group_open_periods(apps: StateApps, schema_editor: BaseDatabaseSchemaEditor) -> None:
    Group = apps.get_model("sentry", "Group")

    backfill_key = "backfill_group_open_periods_from_activity"
    redis_client = redis.redis_clusters.get(settings.SENTRY_MONITORS_REDIS_CLUSTER)

    progress_id = int(redis_client.get(backfill_key) or 0)
    for group_data in chunked(
        RangeQuerySetWrapperWithProgressBarApprox(
            Group.objects.filter(id__gt=progress_id).values_list(
                "id", "first_seen", "status", "project_id"
            ),
            result_value_getter=lambda item: item[0],
        ),
        CHUNK_SIZE,
    ):
        logger.info(
            "Processing batch for group open period backfill",
            extra={"last_group_id": group_data[-1][0]},
        )
        _backfill_group_open_periods(apps, group_data)
        # Save progress to redis in case we have to restart
        redis_client.set(backfill_key, group_data[-1][0], ex=60 * 60 * 24 * 7)


class Migration(CheckedMigration):
    # This flag is used to mark that a migration shouldn't be automatically run in production.
    # This should only be used for operations where it's safe to run the migration after your
    # code has deployed. So this should not be used for most operations that alter the schema
    # of a table.
    # Here are some things that make sense to mark as post deployment:
    # - Large data migrations. Typically we want these to be run manually so that they can be
    #   monitored and not block the deploy for a long period of time while they run.
    # - Adding indexes to large tables. Since this can take a long time, we'd generally prefer to
    #   run this outside deployments so that we don't block them. Note that while adding an index
    #   is a schema change, it's completely safe to run the operation after the code has deployed.
    # Once deployed, run these manually via: https://develop.sentry.dev/database-migrations/#migration-deployment

    is_post_deployment = True

    dependencies = [
        ("sentry", "0877_integer_drift_release"),
    ]

    operations = [
        migrations.RunPython(
            backfill_group_open_periods,
            migrations.RunPython.noop,
            hints={"tables": ["sentry_groupopenperiod"]},
        ),
    ]
