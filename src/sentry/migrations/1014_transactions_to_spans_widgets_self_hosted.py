# Generated by Django 5.2.8 on 2025-12-04 15:11


from enum import Enum

import sentry_sdk
from django.db import migrations
from django.db.backends.base.schema import BaseDatabaseSchemaEditor
from django.db.migrations.state import StateApps
from django.db.models import Q

from sentry.explore.translation.dashboards_translation import (
    restore_transaction_widget,
    translate_dashboard_widget,
)
from sentry.models.dashboard_widget import DashboardWidget
from sentry.new_migrations.migrations import CheckedMigration
from sentry.utils.query import RangeQuerySetWrapperWithProgressBar


class TypesClass:
    TYPES: list[tuple[int, str]]

    @classmethod
    def as_choices(cls) -> list[tuple[int, str]]:
        return [(k, str(v)) for k, v in cls.TYPES]

    @classmethod
    def as_text_choices(cls) -> list[tuple[str, str]]:
        return [(str(v), str(v)) for _, v in cls.TYPES]

    @classmethod
    def get_type_name(cls, num) -> str | None:
        for id, name in cls.TYPES:
            if id == num:
                return name

    @classmethod
    def get_id_for_type_name(cls, type_name) -> int | None:
        for id, name in cls.TYPES:
            if type_name == name:
                return id


class DashboardWidgetTypes(TypesClass):
    DISCOVER = 0
    """
    Old way of accessing error events and transaction events simultaneously @deprecated. Use ERROR_EVENTS or TRANSACTION_LIKE instead.
    """
    ISSUE = 1
    RELEASE_HEALTH = 2
    METRICS = 3
    ERROR_EVENTS = 100
    """
     Error side of the split from Discover.
    """
    TRANSACTION_LIKE = 101
    """
    This targets transaction-like data from the split from discover. Itt may either use 'Transactions' events or 'PerformanceMetrics' depending on on-demand, MEP metrics, etc.
    """
    SPANS = 102
    """
    These represent the logs trace item type on the EAP dataset.
    """
    LOGS = 103
    """
    These represent the tracemetrics item type on the EAP dataset.
    """
    TRACEMETRICS = 104

    TYPES = [
        (DISCOVER, "discover"),
        (ISSUE, "issue"),
        (
            RELEASE_HEALTH,
            "metrics",
        ),
        (ERROR_EVENTS, "error-events"),
        (TRANSACTION_LIKE, "transaction-like"),
        (SPANS, "spans"),
        (LOGS, "logs"),
        (TRACEMETRICS, "tracemetrics"),
    ]
    TYPE_NAMES = [t[1] for t in TYPES]


class DatasetSourcesTypes(Enum):
    """
    Ambiguous queries that haven't been or couldn't be categorized into a
    specific dataset.
    """

    UNKNOWN = 0
    """
     Dataset inferred by either running the query or using heuristics.
    """
    INFERRED = 1
    """
     Canonical dataset, user explicitly selected it.
    """
    USER = 2
    """
     Was an ambiguous dataset forced to split (i.e. we picked a default)
    """
    FORCED = 3
    """
     Dataset inferred by split script, version 1
    """
    SPLIT_VERSION_1 = 4
    """
     Dataset inferred by split script, version 2
    """
    SPLIT_VERSION_2 = 5
    """
     Dataset modified by transaction -> span migration
    """
    SPAN_MIGRATION_VERSION_1 = 6
    """
     Dataset modified by using the widget snapshot to restore the original transaction query
    """
    RESTORED_SPAN_MIGRATION_VERSION_1 = 7
    """
     Dataset modified by the transaction -> span migration version 2
    """
    SPAN_MIGRATION_VERSION_2 = 8
    """
    Dataset modified by the transaction -> span migration version 3
    """
    SPAN_MIGRATION_VERSION_3 = 9
    """
    Dataset modified by the transaction -> span migration version 4 (fixing boolean bug)
    """
    SPAN_MIGRATION_VERSION_4 = 10
    """
    Dataset modified by the transaction -> span migration version 5 (fixing boolean bug again)
    """
    SPAN_MIGRATION_VERSION_5 = 11

    @classmethod
    def as_choices(cls) -> tuple[tuple[int, str], ...]:
        return tuple((source.value, source.name.lower()) for source in cls)

    @classmethod
    def as_text_choices(cls) -> tuple[tuple[str, int], ...]:
        return tuple((source.name.lower(), source.value) for source in cls)


def migrate_transactions_to_spans_widgets_self_hosted(
    apps: StateApps, schema_editor: BaseDatabaseSchemaEditor
) -> None:

    qs = DashboardWidget.objects.filter(
        Q(widget_type=DashboardWidgetTypes.TRANSACTION_LIKE)
        | Q(
            widget_type=DashboardWidgetTypes.DISCOVER,
            discover_widget_split=DashboardWidgetTypes.TRANSACTION_LIKE,
        )
    )

    for widget in RangeQuerySetWrapperWithProgressBar(qs):
        try:
            translate_dashboard_widget(widget)
        except Exception as e:
            sentry_sdk.capture_exception(e)


def reverse_migrate_transactions_to_spans_widgets_self_hosted(
    apps: StateApps, schema_editor: BaseDatabaseSchemaEditor
) -> None:

    qs = DashboardWidget.objects.filter(
        widget_type=DashboardWidgetTypes.SPANS,
        dataset_source__in=[
            DatasetSourcesTypes.SPAN_MIGRATION_VERSION_1.value,
            DatasetSourcesTypes.SPAN_MIGRATION_VERSION_2.value,
            DatasetSourcesTypes.SPAN_MIGRATION_VERSION_3.value,
            DatasetSourcesTypes.SPAN_MIGRATION_VERSION_4.value,
            DatasetSourcesTypes.SPAN_MIGRATION_VERSION_5.value,
        ],
    )

    for widget in RangeQuerySetWrapperWithProgressBar(qs):
        try:
            restore_transaction_widget(widget)
        except Exception as e:
            sentry_sdk.capture_exception(e)


class Migration(CheckedMigration):
    # This flag is used to mark that a migration shouldn't be automatically run in production.
    # This should only be used for operations where it's safe to run the migration after your
    # code has deployed. So this should not be used for most operations that alter the schema
    # of a table.
    # Here are some things that make sense to mark as post deployment:
    # - Large data migrations. Typically we want these to be run manually so that they can be
    #   monitored and not block the deploy for a long period of time while they run.
    # - Adding indexes to large tables. Since this can take a long time, we'd generally prefer to
    #   run this outside deployments so that we don't block them. Note that while adding an index
    #   is a schema change, it's completely safe to run the operation after the code has deployed.
    # Once deployed, run these manually via: https://develop.sentry.dev/database-migrations/#migration-deployment

    is_post_deployment = True

    dependencies = [
        ("sentry", "1013_add_repositorysettings_table"),
    ]

    operations = [
        migrations.RunPython(
            migrate_transactions_to_spans_widgets_self_hosted,
            reverse_code=reverse_migrate_transactions_to_spans_widgets_self_hosted,
            hints={"tables": ["sentry_dashboardwidget"]},
        )
    ]
