# Generated by Django 5.1.7 on 2025-05-06 22:16
from hashlib import md5
from typing import Any

from django.db import migrations
from django.db.backends.base.schema import BaseDatabaseSchemaEditor
from django.db.migrations.state import StateApps

from sentry.new_migrations.migrations import CheckedMigration
from sentry.utils.query import RangeQuerySetWrapperWithProgressBar

DATA_SOURCE_UPTIME_SUBSCRIPTION = "uptime_subscription"


def get_project_subscription(ProjectUptimeSubscription: Any, detector: Any) -> Any:
    data_source = detector.data_sources.first()
    return ProjectUptimeSubscription.objects.get(uptime_subscription_id=int(data_source.source_id))


def build_detector_fingerprint_component(detector: Any) -> str:
    return f"uptime-detector:{detector.id}"


def build_subscription_fingerprint_component(subscription_id: int) -> str:
    return str(subscription_id)


def hash_fingerprint(fingerprint: str) -> str:
    return md5(fingerprint.encode("utf-8")).hexdigest()


def update_auto_detected_active_interval_seconds(
    apps: StateApps, schema_editor: BaseDatabaseSchemaEditor
) -> None:
    GroupHash = apps.get_model("sentry", "GroupHash")
    DataSource = apps.get_model("workflow_engine", "DataSource")
    ProjectUptimeSubscription = apps.get_model("uptime", "ProjectUptimeSubscription")

    for data_source in RangeQuerySetWrapperWithProgressBar(
        DataSource.objects.filter(type=DATA_SOURCE_UPTIME_SUBSCRIPTION)
    ):
        uptime_subscription_id = int(data_source.source_id)
        try:
            project_subscription_id = ProjectUptimeSubscription.objects.get(
                uptime_subscription_id=uptime_subscription_id
            ).id
        except ProjectUptimeSubscription.DoesNotExist:
            continue
        detector = data_source.detectors.first()

        detector_fingerprint_hash = hash_fingerprint(build_detector_fingerprint_component(detector))
        sub_fingerprint_hash = hash_fingerprint(
            build_subscription_fingerprint_component(project_subscription_id)
        )
        group_hashes = list(
            GroupHash.objects.filter(
                project=detector.project,
                hash__in=[detector_fingerprint_hash, sub_fingerprint_hash],
            )
        )
        # If we have 0 or 2 group hashes then we don't need to backfill anything. Either the group doesn't exist
        # at all for this detector, or both hashes are already associated
        if len(group_hashes) != 1:
            continue
        group_hash = group_hashes[0]
        # If the only hash that exists is for the detector fingerprint then we don't have any work to do
        if group_hash.hash == detector_fingerprint_hash:
            continue

        GroupHash.objects.get_or_create(
            project=detector.project,
            hash=detector_fingerprint_hash,
            defaults={
                "group": group_hash.group,
            },
        )


class Migration(CheckedMigration):
    # This flag is used to mark that a migration shouldn't be automatically run in production.
    # This should only be used for operations where it's safe to run the migration after your
    # code has deployed. So this should not be used for most operations that alter the schema
    # of a table.
    # Here are some things that make sense to mark as post deployment:
    # - Large data migrations. Typically we want these to be run manually so that they can be
    #   monitored and not block the deploy for a long period of time while they run.
    # - Adding indexes to large tables. Since this can take a long time, we'd generally prefer to
    #   run this outside deployments so that we don't block them. Note that while adding an index
    #   is a schema change, it's completely safe to run the operation after the code has deployed.
    # Once deployed, run these manually via: https://develop.sentry.dev/database-migrations/#migration-deployment

    is_post_deployment = True

    dependencies = [
        ("uptime", "0040_uptime_backfill_detector_conditions"),
        # ("workflow_engine", "0055_datasource_define_indexes"),
    ]

    operations = [
        migrations.RunPython(
            update_auto_detected_active_interval_seconds,
            migrations.RunPython.noop,
            hints={"tables": ["sentry_grouphash"]},
        )
    ]
