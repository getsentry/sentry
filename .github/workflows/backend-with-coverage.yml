name: backend - with test coverage

on: [workflow_dispatch, workflow_call, pull_request]

jobs:
  files-changed:
    name: detect what files changed
    runs-on: ubuntu-24.04
    timeout-minutes: 3
    outputs:
      backend: ${{ steps.changes.outputs.backend_all }}
    steps:
      - uses: actions/checkout@692973e3d937129bcbf40652eb9f2f61becf3332 # v4.1.7

      - name: Check for backend file changes
        uses: dorny/paths-filter@0bc4621a3135347011ad047f9ecf449bf72ce2bd # v3.0.0
        id: changes
        with:
          token: ${{ github.token }}
          filters: .github/file-filters.yml

  calculate-shards:
    if: needs.files-changed.outputs.backend == 'true'
    needs: files-changed
    name: calculate test shards
    runs-on: ubuntu-24.04
    timeout-minutes: 5
    outputs:
      shard-count: ${{ steps.calculate-shards.outputs.shard-count }}
      shard-indices: ${{ steps.calculate-shards.outputs.shard-indices }}
    steps:
      - uses: actions/checkout@692973e3d937129bcbf40652eb9f2f61becf3332 # v4.1.7

      - name: Setup sentry env
        uses: ./.github/actions/setup-sentry
        id: setup
        with:
          mode: backend-ci
          skip-devservices: true

      - name: Calculate test shards
        id: calculate-shards
        run: python3 .github/workflows/scripts/calculate-backend-test-shards.py

  backend-test-with-cov-context:
    if: needs.files-changed.outputs.backend == 'true'
    name: backend test
    runs-on: ubuntu-24.04
    needs: [files-changed, calculate-shards]
    timeout-minutes: 60
    strategy:
      fail-fast: false
      matrix:
        instance: ${{ fromJSON(needs.calculate-shards.outputs.shard-indices) }}
    env:
      MATRIX_INSTANCE_TOTAL: ${{ needs.calculate-shards.outputs.shard-count }}
      TEST_GROUP_STRATEGY: roundrobin
    steps:
      - uses: actions/checkout@692973e3d937129bcbf40652eb9f2f61becf3332 # v4.1.7

      - name: Setup sentry env
        uses: ./.github/actions/setup-sentry
        id: setup
        with:
          mode: backend-ci

      - name: Run backend test with coverage (${{ steps.setup.outputs.matrix-instance-number }} of ${{ steps.setup.outputs.matrix-instance-total }})
        run: make test-python-ci-with-coverage

      - name: Validate coverage database
        if: always()
        run: |
          set -euxo pipefail
          if [[ ! -f .coverage ]]; then
            echo "Error: No .coverage file found after tests"
            exit 1
          fi
          python -c "import sqlite3; sqlite3.connect('.coverage').execute('SELECT COUNT(*) FROM file')"

      - name: Upload raw coverage sqlite as artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: pycoverage-sqlite-${{ github.run_id }}-${{ steps.setup.outputs.matrix-instance-number }}
          path: .coverage
          if-no-files-found: error
          retention-days: 7
          include-hidden-files: true

  combine-coverage:
    if: needs.files-changed.outputs.backend == 'true'
    name: combine coverage
    runs-on: ubuntu-24.04
    needs: [backend-test-with-cov-context, calculate-shards, files-changed]
    steps:
      - uses: actions/checkout@692973e3d937129bcbf40652eb9f2f61becf3332 # v4.1.7

      - name: Determine commit SHA
        id: commit-info
        run: |
          # For PRs, use the head SHA (the actual commit being tested)
          # For other events (workflow_dispatch, workflow_call), use github.sha
          if [[ "${{ github.event_name }}" == "pull_request" ]]; then
            COMMIT_SHA="${{ github.event.pull_request.head.sha }}"
          else
            COMMIT_SHA="${{ github.sha }}"
          fi
          echo "sha=${COMMIT_SHA}" >> "$GITHUB_OUTPUT"
          echo "short_sha=${COMMIT_SHA:0:12}" >> "$GITHUB_OUTPUT"

      - uses: astral-sh/setup-uv@884ad927a57e558e7a70b92f2bccf9198a4be546 # v6
        with:
          version: '0.8.2'
          enable-cache: false

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.13.1'

      - name: Install coverage
        run: uv pip install --system coverage[toml] covdefaults sentry-covdefaults-disable-branch-coverage

      - name: Download all coverage artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: pycoverage-sqlite-${{ github.run_id }}-*
          path: .artifacts/all-coverage

      - name: List downloaded artifacts (debug)
        run: |
          echo "=== Downloaded artifacts structure ==="
          ls -la .artifacts/all-coverage || true
          find .artifacts/all-coverage -type f || true

      - name: Prepare coverage files for combining
        run: |
          set -euxo pipefail
          mkdir -p .artifacts/to-combine

          find .artifacts/all-coverage -name ".coverage" -type f | while IFS= read -r file; do
            parent_dir=$(basename "$(dirname "$file")")
            instance=$(echo "$parent_dir" | grep -oP '(?<=-)\d+$' || echo "unknown")
            cp -v "$file" ".artifacts/to-combine/.coverage.${instance}"
          done

          echo "=== Files ready for combining ==="
          ls -la .artifacts/to-combine/

      - name: Combine all coverage databases
        run: |
          set -euxo pipefail
          coverage combine .artifacts/to-combine/.coverage.*

          if [[ ! -f .coverage ]]; then
            echo "Error: Combined coverage file was not created"
            exit 1
          fi

          # Rename with commit SHA for identification
          mv .coverage ".coverage.${{ steps.commit-info.outputs.short_sha }}"

      - name: Generate coverage summary (debug)
        run: |
          COVERAGE_FILE=".coverage.${{ steps.commit-info.outputs.short_sha }}"
          python -c "
          import os, sqlite3
          p = '$COVERAGE_FILE'
          print(f'Combined coverage db: {p} ({os.path.getsize(p)} bytes)')
          con = sqlite3.connect(p)
          cur = con.cursor()
          tables = [r[0] for r in cur.execute(\"SELECT name FROM sqlite_master WHERE type='table' ORDER BY 1\").fetchall()]
          print(f'Tables: {tables}')
          print(f'File rows: {cur.execute(\"SELECT COUNT(*) FROM file\").fetchone()[0]}')
          print(f'Context rows: {cur.execute(\"SELECT COUNT(*) FROM context\").fetchone()[0]}')
          "

      - name: Upload combined coverage database (artifact)
        uses: actions/upload-artifact@v4
        with:
          name: pycoverage-sqlite-combined-${{ github.run_id }}
          path: .coverage.${{ steps.commit-info.outputs.short_sha }}
          if-no-files-found: error
          retention-days: 30
          include-hidden-files: true

      - name: Authenticate to Google Cloud
        id: gcloud-auth
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: ${{ secrets.SENTRY_GCP_DEV_WORKLOAD_IDENTITY_POOL }}
          service_account: ${{ secrets.SUDO_GCP_SERVICE_ACCOUNT }}

      - name: Upload coverage to GCS
        uses: google-github-actions/upload-cloud-storage@v2
        with:
          path: .coverage.${{ steps.commit-info.outputs.short_sha }}
          destination: sentry-coverage-data/coverage/${{ steps.commit-info.outputs.sha }}
      - name: Upload coverage  data
        if: '!cancelled()' # Always run this step, unless the workflow was cancelled
        uses: getsentry/action-collect-test-data@v0.3.0
        with:
          path: .coverage.${{ steps.commit-info.outputs.short_sha }}
          gcs_path: sentry-coverage-data/${{ steps.commit-info.outputs.sha }}
          gcp_project_id: sentry-dev-tooling
          workload_identity_provider: ${{ secrets.SENTRY_GCP_DEV_WORKLOAD_IDENTITY_POOL }}
          service_account_email: ${{ secrets.COLLECT_TEST_DATA_SERVICE_ACCOUNT_EMAIL }}
